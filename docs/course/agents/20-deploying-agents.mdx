---
title: "Deploying Agents"
description: "How to deploy and share your AI agents with others"
icon: "rocket"
---

# Deploying Agents

After creating your AI agents, the next step is deploying them for use by yourself or others. In this final lesson, we'll explore different deployment options and best practices.

## Deployment Options

There are several ways to deploy your AI agents:

### 1. Local Deployment

Running your agents locally is the simplest approach:

```python
from praisonaiagents import Agent

def run_local_agent():
    agent = Agent(
        name="SimpleAgent",
        instructions="You are a helpful assistant that answers questions concisely.",
        llm="gpt-4o-mini"  # Using the specified model
    )
    
    while True:
        user_input = input("Ask a question (type 'exit' to quit): ")
        if user_input.lower() == 'exit':
            break
        
        response = agent.start(user_input)
        print("\nAgent response:")
        print(response)
        print("\n" + "-"*50 + "\n")

if __name__ == "__main__":
    run_local_agent()
```

### 2. Web Application Deployment

You can deploy your agents as part of a web application:

```python
from flask import Flask, request, jsonify
from praisonaiagents import Agent
import os

app = Flask(__name__)

# Create agent once at startup
support_agent = Agent(
    name="SupportAgent",
    instructions="You are a customer support agent that helps users with product questions.",
    llm="gpt-4o-mini"  # Using the specified model
)

@app.route('/api/support', methods=['POST'])
def get_support():
    data = request.json
    user_query = data.get('query', '')
    
    if not user_query:
        return jsonify({"error": "No query provided"}), 400
    
    try:
        response = support_agent.start(user_query)
        return jsonify({"response": response})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(debug=True, port=5000)
```

### 3. Serverless Function Deployment

For scalable, event-driven deployments, serverless functions work well:

```python
# Example AWS Lambda function
import json
from praisonaiagents import Agent

# Initialize agent outside the handler for reuse across invocations
agent = Agent(
    name="ServerlessAgent",
    instructions="You provide concise, helpful responses to user questions.",
    llm="gpt-4o-mini"  # Using the specified model
)

def lambda_handler(event, context):
    try:
        # Get the user query from the event
        body = json.loads(event.get('body', '{}'))
        user_query = body.get('query', '')
        
        if not user_query:
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'No query provided'})
            }
        
        # Process with the agent
        response = agent.start(user_query)
        
        return {
            'statusCode': 200,
            'body': json.dumps({'response': response})
        }
    except Exception as e:
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }
```

## Environment Variables and Security

When deploying agents, it's crucial to handle API keys and secrets securely:

```python
import os
from dotenv import load_dotenv
from praisonaiagents import Agent

# Load environment variables from .env file
load_dotenv()

# Access API key from environment variable
api_key = os.getenv("OPENAI_API_KEY")

# Create agent with API key
agent = Agent(
    name="SecureAgent",
    instructions="You are a helpful assistant.",
    llm="gpt-4o-mini",  # Using the specified model
    api_key=api_key  # Pass API key securely
)
```

## Creating a Simple Chat Interface

Here's a simple command-line chat interface for your agent:

```python
import os
from praisonaiagents import Agent

def create_chat_interface():
    # Initialize agent
    agent = Agent(
        name="ChatAgent",
        instructions="""
        You are a conversational assistant that maintains context throughout the conversation.
        Respond in a helpful, concise manner.
        """,
        llm="gpt-4o-mini"  # Using the specified model
    )
    
    print("Chat with AI Assistant (type 'exit' to quit)")
    print("-" * 50)
    
    # Start conversation
    conversation_active = True
    first_message = True
    
    while conversation_active:
        # Get user input
        user_message = input("You: ")
        
        # Check if user wants to exit
        if user_message.lower() == 'exit':
            print("Goodbye!")
            conversation_active = False
            continue
        
        # Get agent response
        try:
            if first_message:
                response = agent.start(user_message)
                first_message = False
            else:
                response = agent.continue(user_message)
            
            print("\nAssistant:", response)
            print("\n" + "-" * 50)
        except Exception as e:
            print(f"Error: {str(e)}")
    
if __name__ == "__main__":
    create_chat_interface()
```

## Scaling Considerations

As you deploy agents for wider use, consider these scaling factors:

<CardGroup cols={2}>
  <Card title="Rate Limiting" icon="gauge-high">
    Implement rate limiting to manage API usage and costs
  </Card>
  <Card title="Caching" icon="database">
    Cache common responses to improve performance and reduce API calls
  </Card>
  <Card title="Error Handling" icon="triangle-exclamation">
    Implement robust error handling for API failures
  </Card>
  <Card title="Monitoring" icon="chart-line">
    Set up monitoring for usage patterns and performance issues
  </Card>
</CardGroup>

## Best Practices for Deployment

### 1. Testing Before Deployment

Always test your agents thoroughly before deployment:

```python
def test_agent_functionality():
    """Test basic agent functionality with various inputs"""
    agent = Agent(
        name="TestAgent",
        instructions="You are a helpful assistant for testing.",
        llm="gpt-4o-mini"  # Using the specified model
    )
    
    test_cases = [
        "What is artificial intelligence?",
        "How do I reset my password?",
        "Tell me about machine learning"
    ]
    
    for test_case in test_cases:
        print(f"\nTesting: {test_case}")
        response = agent.start(test_case)
        print(f"Response: {response[:100]}...")  # Print first 100 chars
        
        # Add assertions or validation logic here
        assert len(response) > 0, "Response should not be empty"
```

### 2. Documentation

Create clear documentation for users of your agent:

```python
"""
# Customer Support Agent API

This API provides access to an AI customer support agent
that can answer questions about our products.

## Authentication

Include your API key in the request header:
```
Authorization: Bearer YOUR_API_KEY
```

## Endpoints

POST /api/support
- Request body: {"query": "Your question here"}
- Response: {"response": "Agent's answer"}

## Example

```python
import requests

response = requests.post(
    "https://api.example.com/api/support",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={"query": "How do I reset my password?"}
)

print(response.json())
```
"""
```

### 3. Version Control

Implement version control for your agents to track changes:

```python
class VersionedAgent:
    def __init__(self, name, version, instructions):
        self.name = name
        self.version = version
        self.agent = Agent(
            name=f"{name}_v{version}",
            instructions=instructions,
            llm="gpt-4o-mini"  # Using the specified model
        )
    
    def get_response(self, query):
        response = self.agent.start(query)
        return {
            "agent_name": self.name,
            "version": self.version,
            "response": response,
            "timestamp": datetime.now().isoformat()
        }
```

## Conclusion

Congratulations on completing the AI Agents Course! You've learned how to:

1. Understand different types of AI agents and their architectures
2. Create effective agent instructions and tools
3. Implement memory and context for your agents
4. Build specialized agents for various tasks
5. Create multi-agent systems
6. Deploy your agents for real-world use

As AI agent technology continues to evolve, keep experimenting with new capabilities and use cases. Remember that the best agents are those that effectively solve real problems for users while being trustworthy, reliable, and helpful.

We hope this course has provided you with the knowledge and skills to build powerful AI agents that enhance productivity and creativity!

## Next Steps

<CardGroup cols={2}>
  <Card title="Join the Community" icon="users">
    Participate in discussions and share your agent projects
  </Card>
  <Card title="Stay Updated" icon="newspaper">
    Follow updates in AI agent technology and new features
  </Card>
  <Card title="Share Your Feedback" icon="comment">
    Let us know how you're using agents and what you'd like to learn next
  </Card>
  <Card title="Build Real Solutions" icon="lightbulb">
    Apply your knowledge to build solutions for real-world problems
  </Card>
</CardGroup>
